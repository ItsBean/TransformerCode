# Transformer for Latin to English Translation

In this tutorial, we dive deep into building a translation model using the Transformer architecture. Specifically, we'll focus on **Latin to English translation**. Here's a brief overview:

- **Dataset**: Our primary dataset for this tutorial is centered on Latin-English translations. It offers a comprehensive set of sentence pairs that will be pivotal in training a robust model.

- **Training and Data Processing**: In the provided `train.py` file, not only do we guide you through the steps to construct and train the Transformer model, but we also delve into preprocessing the raw dataset. This ensures that you understand how to curate and prepare the data for optimal training results.

- **Model Definition**: The `harvard_transformer.py` file is where the magic happens. Here, we've defined the Transformer architecture, encapsulating all its intricate layers and functionalities. Familiarizing yourself with this file will give you a thorough understanding of how the Transformer model is structured and operates.

We hope this tutorial enlightens you on the nuances of machine translation and empowers you to build upon this knowledge. Happy coding!
